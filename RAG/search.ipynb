{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73ca1cbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ì¹´ë“œ ì¶”ì²œ ì±—ë´‡ ===\n",
      "\n",
      "ì§ˆë¬¸ : ì—°íšŒë¹„ 5ë§Œì› ì´ìƒì˜ ì‚¼ì„±ì¹´ë“œì¤‘ ë¹„ìì¹´ë“œ ì¶”ì²œí•´ì¤˜\n",
      "\n",
      "[ì¹´ë“œ ì¶”ì²œ ê²°ê³¼]\n",
      "ì¹´ë“œëª…: THE O V2 (í¬ì¸íŠ¸)  \n",
      "ì¹´ë“œì‚¬: ì‚¼ì„±ì¹´ë“œ  \n",
      "ì—°íšŒë¹„(êµ­ë‚´): 595,000ì›  \n",
      "ì—°íšŒë¹„(í•´ì™¸): 600,000ì›  \n",
      "ê¸€ë¡œë²Œë¸Œëœë“œ: visa  \n",
      "url: https://www.card-gorilla.com/card/detail/1904  \n",
      "í˜œíƒ:  \n",
      "- ì—° 1íšŒ 11ê°€ì§€ í”„ë¦¬ë¯¸ì—„ ê¸°í”„íŠ¸(í•­ê³µê¶Œ, í˜¸í…”, ê³¨í”„, ì‡¼í•‘ ë“±) ì¤‘ íƒ1 (ìµœëŒ€ 35ë§Œì› ìƒë‹¹)  \n",
      "- ëª¨ë“  ê°€ë§¹ì  1.2% ë¹…í¬ì¸íŠ¸ ì ë¦½ (í•œë„ ì—†ì´ ì œê³µ)  \n",
      "- 10ëŒ€ ì»¤í”¼ì „ë¬¸ì  20% ì²­êµ¬í• ì¸(ì›” 1ë§Œì› í•œë„, ì „ì›” 50ë§Œì› ì´ìƒ ì´ìš© ì‹œ)  \n",
      "- ì˜í™”ê´€ 5,000ì› ì²­êµ¬í• ì¸(ì›” 1íšŒ, ì „ì›” 50ë§Œì› ì´ìƒ ì´ìš© ì‹œ)  \n",
      "- íƒì‹œ 3,000ì› ì²­êµ¬í• ì¸(ì›” 1íšŒ, ì „ì›” 50ë§Œì› ì´ìƒ ì´ìš© ì‹œ)  \n",
      "- êµ­ë‚´ì™¸ ê³µí•­ ë¼ìš´ì§€ ë¬´ë£Œ, ê³µí•­ ë° í˜¸í…” ë°œë ›íŒŒí‚¹ ë¬´ë£Œ, Visa Infinite í”„ë¦¬ë¯¸ì—„ ì„œë¹„ìŠ¤  \n",
      "- ì „ì›” ì‹¤ì  ì¡°ê±´: ì¼ë¶€ ì„œë¹„ìŠ¤ëŠ” ì „ì›” ì¼ì‹œë¶ˆ/í• ë¶€ 50ë§Œì› ì´ìƒ ì´ìš© ì‹œ ì œê³µ\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8605591e740475999acd27632430630",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ì •í™•ë„ í‰ê°€ ê²°ê³¼ (RAGAS)]\n",
      "   answer_relevancy\n",
      "0          0.756955\n",
      "----------------------------------------\n",
      "\n",
      "ì›í•˜ëŠ” ë™ì‘ì„ ì„ íƒí•˜ì„¸ìš”:\n",
      "1. ì¬ê²€ìƒ‰(ìƒˆë¡œìš´ ì¿¼ë¦¬)\n",
      "2. ì¢…ë£Œ\n",
      "ì˜ëª»ëœ ì…ë ¥ì…ë‹ˆë‹¤. ë‹¤ì‹œ ì„ íƒí•´ ì£¼ì„¸ìš”.\n",
      "\n",
      "ì›í•˜ëŠ” ë™ì‘ì„ ì„ íƒí•˜ì„¸ìš”:\n",
      "1. ì¬ê²€ìƒ‰(ìƒˆë¡œìš´ ì¿¼ë¦¬)\n",
      "2. ì¢…ë£Œ\n",
      "ì§ˆë¬¸ : ì—°íšŒë¹„ê°€ 5ë§Œì› ì´ìƒ, 10ë§Œì› ì´í•˜ë©´ì„œ, VISA ë¸Œëœë“œì´ë©´ì„œ ì‚¼ì„±ì¹´ë“œì¸ ê²ƒì„ ì¶”ì²œí•´ì¤˜\n",
      "\n",
      "[ì¹´ë“œ ì¶”ì²œ ê²°ê³¼]\n",
      "**ì •ë³´ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤**\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ccc7e02329c4781941fad4c5cabb2cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ì •í™•ë„ í‰ê°€ ê²°ê³¼ (RAGAS)]\n",
      "   answer_relevancy\n",
      "0               0.0\n",
      "----------------------------------------\n",
      "\n",
      "ì›í•˜ëŠ” ë™ì‘ì„ ì„ íƒí•˜ì„¸ìš”:\n",
      "1. ì¬ê²€ìƒ‰(ìƒˆë¡œìš´ ì¿¼ë¦¬)\n",
      "2. ì¢…ë£Œ\n",
      "\n",
      "í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from pinecone import Pinecone\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableLambda, RunnableMap, RunnablePassthrough\n",
    "from datasets import Dataset\n",
    "from ragas import evaluate\n",
    "from ragas.metrics import faithfulness, answer_relevancy\n",
    "\n",
    "# 1) í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
    "PINECONE_ENV = os.getenv(\"PINECONE_ENV\")\n",
    "INDEX_NAME = \"card-index\"\n",
    "\n",
    "# 2) ì¹´ë“œ ë°ì´í„° ë¡œë“œ\n",
    "with open(\"cards.json\", encoding=\"utf-8\") as f:\n",
    "    cards = json.load(f)\n",
    "card_lookup = {str(card[\"id\"]): card for card in cards}\n",
    "\n",
    "# 3) Pinecone ì´ˆê¸°í™” ë° ì„ë² ë”© ì¤€ë¹„\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY, environment=PINECONE_ENV)\n",
    "pinecone_index = pc.Index(INDEX_NAME)\n",
    "embedder = OpenAIEmbeddings(model=\"text-embedding-3-small\", openai_api_key=OPENAI_API_KEY)\n",
    "\n",
    "# 4) LLM, íŒŒì„œ ì¤€ë¹„\n",
    "llm = ChatOpenAI(model_name=\"gpt-4.1\", openai_api_key=OPENAI_API_KEY)\n",
    "parser = StrOutputParser()\n",
    "\n",
    "# --- ì¿¼ë¦¬ í™•ì¥ í•¨ìˆ˜ --- #\n",
    "def expand_queries(base_query: str) -> list[str]:\n",
    "    prompt = (\n",
    "        f\"ì§ˆë¬¸: {base_query}\\n\"\n",
    "        \"ìœ„ ì§ˆë¬¸ê³¼ 'ì˜ë¯¸ëŠ” ê°™ì§€ë§Œ' í‘œí˜„ ë°©ì‹ë§Œ ë‹¤ë¥¸ ì§ˆë¬¸ì„ 4ê°œ ìƒì„±í•´ì¤˜. \"\n",
    "        \"ê° ì§ˆë¬¸ì€ ì›ë˜ ì§ˆë¬¸ì˜ ì¡°ê±´(ë¸Œëœë“œ, ì—°íšŒë¹„, í˜œíƒ ë“±)ì„ ëª¨ë‘ ë°˜ë“œì‹œ í¬í•¨í•´ì•¼ í•´. \"\n",
    "        \"ì¹´ë“œ í˜œíƒ ì¶”ì²œì— ì‚¬ìš©í•  ê²ƒì´ê³ , ë„ˆë¬´ ë‘ë£¨ë­‰ìˆ í•˜ê²Œ ë§í•˜ì§€ ë§ê³ , ê°ê° ë‹¤ë¥¸ ë‹¨ì–´, ì–´ìˆœ, í‘œí˜„ë²•ì„ ì¨ì¤˜. \"\n",
    "        \"ë‹µë³€ì€ ì•„ë˜ì™€ ê°™ì´ ë²ˆí˜¸ ì—†ì´ í•œ ì¤„ì”© ì¶œë ¥í•´ì¤˜.\\n\"\n",
    "        \"- ì˜ˆ: ë°°ë‹¬ìŒì‹ í• ì¸ ì¹´ë“œ ì¶”ì²œí•´ì¤˜\\n\"\n",
    "        \"- ì˜ˆ: ë°°ë‹¬ì•± í• ì¸ ì‹ ìš©ì¹´ë“œ ì¤‘ ì¢‹ì€ ê±° ìˆì–´?\\n\"\n",
    "    )\n",
    "    response = llm.invoke(prompt)\n",
    "    queries = [base_query] + [line.strip(\"- \") for line in response.content.strip().splitlines() if line.strip()]\n",
    "    return queries[:5]\n",
    "\n",
    "# --- LLMì—ì„œ ë©”íƒ€ë°ì´í„° í•„í„° ì¶”ì¶œ (í”„ë¡¬í”„íŠ¸ ê°•í™”) --- #\n",
    "def get_filter_json_via_llm(query: str) -> dict:\n",
    "    prompt = f\"\"\"\n",
    "ì•„ë˜ \"ì§ˆë¬¸\"ì—ì„œ **ëª…ì‹œì ìœ¼ë¡œ ë“œëŸ¬ë‚œ** ì¹´ë“œ ì¡°ê±´ë§Œ JSONìœ¼ë¡œ ì¶”ì¶œí•´ì¤˜.\n",
    "ì¹´ë“œëª…/ì¹´ë“œì‚¬/ë¸Œëœë“œ/ì—°íšŒë¹„ ê°™ì€ íŠ¹ì • ê°’ì€ **ì§ˆë¬¸ì— ì§ì ‘ ë“±ì¥í•  ë•Œë§Œ** ì±„ì›Œì¤˜.\n",
    "ì§ˆë¬¸ì— ë“±ì¥í•˜ì§€ ì•Šì€ í•­ëª©ì€ nullë¡œ ë‚¨ê²¨.\n",
    "íŠ¹ì • ì¹´ë“œëª…/ë¸Œëœë“œ/ì—°íšŒë¹„ëŠ” **ì¶”ì •, ì˜ˆì‹œ ì¶”ê°€ ì ˆëŒ€ ê¸ˆì§€**.\n",
    "ë¦¬ìŠ¤íŠ¸/ë°°ì—´ í˜•íƒœë„ ê¸ˆì§€. ë°˜ë“œì‹œ í•˜ë‚˜ì˜ ë”•ì…”ë„ˆë¦¬(JSON)ë§Œ ì¶œë ¥.\n",
    "ì˜ˆì‹œ:\n",
    "ì§ˆë¬¸: ë°°ë‹¬ í˜œíƒ ë§ì€ ì¹´ë“œ ì¶”ì²œí•´ì¤˜\n",
    "â†’\n",
    "{{\n",
    "  \"name\": null,\n",
    "  \"brand\": null,\n",
    "  \"global_brand\": null,\n",
    "  \"fee_domestic\": null,\n",
    "  \"fee_global\": null\n",
    "}}\n",
    "ì§ˆë¬¸: ì—°íšŒë¹„ 5ë§Œì› ì´í•˜ì˜ ì‚¼ì„±ì¹´ë“œ ì¶”ì²œí•´ì¤˜\n",
    "â†’\n",
    "{{\n",
    "  \"name\": null,\n",
    "  \"brand\": \"ì‚¼ì„±ì¹´ë“œ\",\n",
    "  \"global_brand\": null,\n",
    "  \"fee_domestic\": {{\"op\": \"lte\", \"value\": 50000}},\n",
    "  \"fee_global\": {{\"op\": \"lte\", \"value\": 50000}}\n",
    "}}\n",
    "ì§ˆë¬¸: í˜„ëŒ€ì¹´ë“œ ì¤‘ ì—°íšŒë¹„ 2ë§Œì› ì´í•˜, Visa ë¸Œëœë“œ ì¶”ì²œí•´ì¤˜\n",
    "â†’\n",
    "{{\n",
    "  \"name\": null,\n",
    "  \"brand\": \"í˜„ëŒ€ì¹´ë“œ\",\n",
    "  \"global_brand\": \"Visa\",\n",
    "  \"fee_domestic\": {{\"op\": \"lte\", \"value\": 20000}},\n",
    "  \"fee_global\": {{\"op\": \"lte\", \"value\": 20000}}\n",
    "}}\n",
    "\n",
    "ì§ˆë¬¸: {query}\n",
    "ë°˜ë“œì‹œ ìœ„ ì˜ˆì‹œ í¬ë§·ì„ ë”°ë¥´ê³ , JSON ì™¸ ë‹¤ë¥¸ ì¶œë ¥ ì ˆëŒ€ ê¸ˆì§€.\n",
    "ë§Œì•½ ë‘˜ì¤‘í•˜ë‚˜ë¼ë„ ë§Œì¡±í•˜ë©´ ì¶œë ¥ê°€ëŠ¥í•˜ê²Œë”.\n",
    "\"\"\"\n",
    "    response = llm.invoke(prompt)\n",
    "    raw = response.content.strip()\n",
    "\n",
    "    # ë°±í‹± ì œê±°\n",
    "    if raw.startswith(\"```json\") or raw.startswith(\"```\"):\n",
    "        raw = re.sub(r\"```(?:json)?\", \"\", raw).strip()\n",
    "        raw = raw.rstrip(\"`\").strip()\n",
    "    try:\n",
    "        result = json.loads(raw)\n",
    "        if isinstance(result, list) and len(result) > 0 and isinstance(result[0], dict):\n",
    "            result = result[0]\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        print(\"LLM JSON íŒŒì‹± ì‹¤íŒ¨:\", e)\n",
    "        print(\"ì‘ë‹µ ë‚´ìš©:\", response.content)\n",
    "        return {}\n",
    "\n",
    "# --- ë©”íƒ€ë°ì´í„° í•„í„° ë³€í™˜ --- #\n",
    "def build_metadata_filter(parsed) -> dict:\n",
    "    if isinstance(parsed, list):\n",
    "        if len(parsed) > 0 and isinstance(parsed[0], dict):\n",
    "            parsed = parsed[0]\n",
    "        else:\n",
    "            return {}\n",
    "\n",
    "    filter_dict = {}\n",
    "    or_conditions = []\n",
    "\n",
    "    if parsed.get(\"name\"):\n",
    "        filter_dict[\"name\"] = {\"$eq\": parsed[\"name\"]}\n",
    "    if parsed.get(\"brand\"):\n",
    "        filter_dict[\"brand\"] = {\"$eq\": parsed[\"brand\"]}\n",
    "    if parsed.get(\"global_brand\"):\n",
    "        filter_dict[\"global_brand\"] = {\"$eq\": parsed[\"global_brand\"]}\n",
    "\n",
    "    # ì—°íšŒë¹„ ì¡°ê±´ì„ ORë¡œ ë¬¶ê¸°\n",
    "    for fee_field, pinecone_field in [(\"fee_domestic\", \"annual_fee_domestic\"), (\"fee_global\", \"annual_fee_global\")]:\n",
    "        fee_obj = parsed.get(fee_field)\n",
    "        if isinstance(fee_obj, dict):\n",
    "            op = fee_obj.get(\"op\")\n",
    "            val = fee_obj.get(\"value\")\n",
    "            if op in [\"lte\", \"gte\", \"eq\"] and isinstance(val, (int, float)):\n",
    "                or_conditions.append({pinecone_field: {f\"${op}\": val}})\n",
    "\n",
    "    # ë‘˜ ë‹¤ ì¡°ê±´ ìˆìœ¼ë©´ ORë¡œ ë¬¶ìŒ\n",
    "    if or_conditions:\n",
    "        if filter_dict:\n",
    "            # AND(ê¸°íƒ€ì¡°ê±´) & OR(ì—°íšŒë¹„)\n",
    "            filter_dict[\"$or\"] = or_conditions\n",
    "            return filter_dict\n",
    "        else:\n",
    "            # ì—°íšŒë¹„ë§Œ ìˆì„ ë•Œ\n",
    "            return {\"$or\": or_conditions}\n",
    "    return filter_dict\n",
    "\n",
    "\n",
    "# --- ì¿¼ë¦¬ ì„ë² ë”© --- #\n",
    "def embed_multiple_queries(queries):\n",
    "    vectors = embedder.embed_documents(queries)\n",
    "    avg_vector = [sum(col) / len(col) for col in zip(*vectors)]\n",
    "    return avg_vector\n",
    "\n",
    "expand_and_embed = RunnableLambda(lambda q: embed_multiple_queries(expand_queries(q)))\n",
    "\n",
    "# --- ìœ ì‚¬ë„ ê²€ìƒ‰ + í•„í„° ì ìš© --- #\n",
    "def search_similar_cards_with_filter(input: dict, k=5):\n",
    "    query = input[\"query\"]\n",
    "    vector = input[\"vector\"]\n",
    "    parsed = get_filter_json_via_llm(query)\n",
    "    metadata_filter = build_metadata_filter(parsed)\n",
    "    if metadata_filter:\n",
    "        resp = pinecone_index.query(vector=vector, top_k=k, include_metadata=True, filter=metadata_filter)\n",
    "    else:\n",
    "        resp = pinecone_index.query(vector=vector, top_k=k, include_metadata=True)\n",
    "    return [card_lookup[match[\"id\"]] for match in resp[\"matches\"] if match[\"id\"] in card_lookup]\n",
    "\n",
    "# --- ì¹´ë“œ ì„¤ëª… í¬ë§· --- #\n",
    "def format_cards(cards):\n",
    "    info_strs = []\n",
    "    for card in cards:\n",
    "        name = card.get(\"name\", \"\")\n",
    "        issuer = card.get(\"brand\", \"\")\n",
    "        card_id = card.get(\"id\", \"\")\n",
    "        annual_domestic = f\"{card.get('annual_fee_domestic', 0):,}\"\n",
    "        annual_global = f\"{card.get('annual_fee_global', 0):,}\"\n",
    "        summary_box = card.get(\"summary_box\", \"\")\n",
    "        benefits = \"\\n\".join(f\"- {b['category']}: {' / '.join(b['details'])}\" for b in card.get(\"benefits\", []))\n",
    "        info_strs.append(\n",
    "            f\"ì¹´ë“œëª…: {name}\\n\"\n",
    "            f\"ì¹´ë“œID: {card_id}\\n\"\n",
    "            f\"ì¹´ë“œì‚¬: {issuer}\\n\"\n",
    "            f\"ì—°íšŒë¹„(êµ­ë‚´): {annual_domestic}ì›\\n\"\n",
    "            f\"ì—°íšŒë¹„(í•´ì™¸): {annual_global}ì›\\n\"\n",
    "            f\"ìš”ì•½: {summary_box}\\n\"\n",
    "            f\"í˜œíƒ:\\n{benefits}\"\n",
    "        )\n",
    "    return \"\\n\\n\".join(info_strs)\n",
    "\n",
    "format_card_text = RunnableLambda(format_cards)\n",
    "\n",
    "# --- í”„ë¡¬í”„íŠ¸ ìƒì„± --- #\n",
    "def make_prompt(input: dict) -> str:\n",
    "    return (\n",
    "        f\"ì§ˆë¬¸: {input['query']}\\n\\n\"\n",
    "        \"ì•„ë˜ ì¹´ë“œ ì •ë³´(context)ì— ëª…ì‹œëœ ë‚´ìš©ë§Œ ì°¸ê³ í•˜ì—¬ ë‹µë³€í•´ ì£¼ì„¸ìš”.\\n\"\n",
    "        \"ì§ˆë¬¸ì— í•´ë‹¹í•˜ëŠ” ì¹´ë“œê°€ ì—¬ëŸ¬ ê°œì—¬ë„ ì•„ë˜ contextì— ë‚˜ì˜¨ ì¹´ë“œ ì¤‘ ì œì¼ ì§ˆë¬¸ì— ì í•©í•œ ì¹´ë“œë¡œ í•œê°œ ì¶”ì²œí•˜ì„¸ìš”.\\n\"\n",
    "        \"contextì— ë‚˜ì™€ ìˆì§€ ì•Šì€ ì •ë³´(ì—°íšŒë¹„, ì¹´ë“œì‚¬, í˜œíƒ ë“±)ëŠ” ì ˆëŒ€ë¡œ ë‹µë³€ì— í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.\\n\"\n",
    "        \"ì¹´ë“œ ì •ë³´ ì™¸ ì¶”ê°€ ì„¤ëª…, ì¼ë°˜ì ì¸ ì•ˆë‚´, ë°°ê²½ì§€ì‹, ìƒìƒ, ìœ ì¶” ë“±ë„ í•˜ì§€ ë§ˆì„¸ìš”.\\n\"\n",
    "        \"ë‹µë³€ì€ ì•„ë˜ contextì— ë‚˜ì™€ ìˆëŠ” ì¹´ë“œ ì •ë³´ ì¤‘ í•˜ë‚˜ì˜ ì „ì²´ ì •ë³´ë¥¼ ê°€ì‹œì ìœ¼ë¡œ ë³´ê¸° ì¢‹ê²Œ ë³´ì—¬ì£¼ì„¸ìš”.\\n\"\n",
    "        \"ë‚´ìš© ìì²´ëŠ” ë„ˆë¬´ ê¸¸ì§€ì•Šê²Œ ì ë‹¹íˆ ìš”ì•½í•´ì„œ ë³´ì—¬ì£¼ì„¸ìš”\\n\"\n",
    "        \"[ì¹´ë“œëª…:00ì¹´ë“œ\\n ì¹´ë“œì‚¬: 00ì¹´ë“œ \\nì—°íšŒë¹„(êµ­ë‚´): 1234ì›\\nì—°íšŒë¹„(í•´ì™¸):1234ì›\\nê¸€ë¡œë²Œë¸Œëœë“œ: visa\\nurl:https://www.card-gorilla.com/card/detail/ì¹´ë“œid\\ní˜œíƒ:\\n\"\n",
    "        \"ìš”ì•½ì€ í•˜ë˜ ìœ„ ê·œê²©ì— ë§ì¶°ì„œ ì¶œë ¥í•´ì£¼ì„¸ìš”.\\n\"\n",
    "        \"ì£¼ì–´ì§„ ë°ì´í„°ì— ì§ˆë¬¸ì— ë§ëŠ” ì¹´ë“œì •ë³´ê°€ ì—†ìœ¼ë©´ **ì •ë³´ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤** ë¼ê³  ì…ë ¥í•´ì£¼ì„¸ìš”\"\n",
    "        f\"{input['cards_block']}\"\n",
    "    )\n",
    "\n",
    "\n",
    "# --- ì²´ì¸ êµ¬ì„± --- #\n",
    "recommend_chain = (\n",
    "    RunnablePassthrough()\n",
    "    | {\"query\": RunnablePassthrough(), \"vector\": expand_and_embed}\n",
    "    | RunnableMap({\n",
    "        \"query\": lambda x: x[\"query\"],\n",
    "        \"cards\": search_similar_cards_with_filter\n",
    "    })\n",
    "    | RunnableMap({\n",
    "        \"query\": lambda x: x[\"query\"],\n",
    "        \"cards_block\": lambda x: format_cards(x[\"cards\"])\n",
    "    })\n",
    "    | RunnableLambda(make_prompt)\n",
    "    | llm\n",
    "    | parser\n",
    ")\n",
    "\n",
    "\n",
    "# --- robust ì¹´ë“œID ì¶”ì¶œ: ì¹´ë“œID â†’ fallback ì¹´ë“œëª… --- #\n",
    "def get_card_ids_from_answer(answer):\n",
    "    \"\"\"\n",
    "    ì¶”ì²œ ê²°ê³¼ì—ì„œ ì¹´ë“œID(ìˆìœ¼ë©´) ì¶”ì¶œ, ì—†ìœ¼ë©´ ì¹´ë“œëª… ê¸°ì¤€ìœ¼ë¡œ cards.jsonì—ì„œ ì°¾ê¸°\n",
    "    \"\"\"\n",
    "    card_ids = []\n",
    "    card_names = []\n",
    "    for line in answer.splitlines():\n",
    "        line_clean = line.strip(\" -\\t\")\n",
    "        # ì¹´ë“œID ì§ì ‘ íŒŒì‹±\n",
    "        if line_clean.startswith(\"ì¹´ë“œID:\"):\n",
    "            cid = line_clean.replace(\"ì¹´ë“œID:\", \"\").strip()\n",
    "            if cid.isdigit():\n",
    "                card_ids.append(cid)\n",
    "        elif line_clean.startswith(\"ì¹´ë“œëª…:\"):\n",
    "            name = line_clean.replace(\"ì¹´ë“œëª…:\", \"\").strip()\n",
    "            card_names.append(name)\n",
    "    # ì¹´ë“œID ìš°ì„ , ì—†ìœ¼ë©´ ì¹´ë“œëª… â†’ card_lookupì—ì„œ ë§¤ì¹­\n",
    "    if not card_ids and card_names:\n",
    "        for name in card_names:\n",
    "            for card in cards:\n",
    "                if card[\"name\"] == name:\n",
    "                    card_ids.append(str(card[\"id\"]))\n",
    "                    break\n",
    "    return card_ids\n",
    "\n",
    "# --- MAIN LOOP --- #\n",
    "def run_single_ragas_eval(query, answer, top_k=5):\n",
    "    \"\"\"ë‹¨ì¼ ì¿¼ë¦¬ì— ëŒ€í•œ ragas í‰ê°€\"\"\"\n",
    "    vector = embed_multiple_queries([query])\n",
    "    resp = pinecone_index.query(vector=vector, top_k=top_k, include_metadata=True)\n",
    "    doc_texts = []\n",
    "    for match in resp[\"matches\"]:\n",
    "        card_id = match[\"id\"]\n",
    "        card = card_lookup.get(card_id)\n",
    "        if card:\n",
    "            doc_texts.append(format_cards([card]))\n",
    "    dataset = Dataset.from_dict({\n",
    "        \"question\": [query],\n",
    "        \"answer\": [answer],\n",
    "        \"contexts\": [doc_texts],\n",
    "    })\n",
    "    result = evaluate(\n",
    "        dataset=dataset,\n",
    "        metrics=[answer_relevancy]\n",
    "    )\n",
    "    return result.to_pandas()\n",
    "\n",
    "def main():\n",
    "    print(\"=== ì¹´ë“œ ì¶”ì²œ ì±—ë´‡ ===\\n\")\n",
    "    while True:\n",
    "        user_query = input(\"\\nğŸ’¬ ì¶”ì²œ ë°›ê³  ì‹¶ì€ ì¹´ë“œë¥¼ ì„¤ëª…í•´ ì£¼ì„¸ìš” (ì¢…ë£Œ: q): \").strip()\n",
    "        if user_query.lower() in (\"q\", \"quit\", \"exit\"):\n",
    "            print(\"\\ní”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.\")\n",
    "            break\n",
    "        # ì¶”ì²œ ê²°ê³¼ í˜¸ì¶œ (ì˜ˆì™¸ì²˜ë¦¬)\n",
    "        try:\n",
    "            answer = recommend_chain.invoke(user_query)\n",
    "        except Exception as e:\n",
    "            print(f\"[ì˜¤ë¥˜] ì¶”ì²œ ê²°ê³¼ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {e}\")\n",
    "            continue\n",
    "\n",
    "        print(f\"ì§ˆë¬¸ : {user_query}\\n\\n[ì¹´ë“œ ì¶”ì²œ ê²°ê³¼]\\n{answer}\\n{'-'*40}\")\n",
    "\n",
    "        # === ì •í™•ë„(RAGAS) í‰ê°€ê²°ê³¼ ìë™ ì¶œë ¥ ===\n",
    "        try:\n",
    "            eval_df = run_single_ragas_eval(user_query, answer)\n",
    "            print(\"[ì •í™•ë„ í‰ê°€ ê²°ê³¼ (RAGAS)]\", flush=True)\n",
    "            print(eval_df[[\"answer_relevancy\"]], flush=True)\n",
    "        except Exception as e:\n",
    "            print(f\"[RAGAS í‰ê°€ ì˜¤ë¥˜] {e}\")\n",
    "        print(\"-\" * 40)\n",
    "\n",
    "        # ë©”ë‰´ ë°˜ë³µ\n",
    "        while True:\n",
    "            print(\"\\nì›í•˜ëŠ” ë™ì‘ì„ ì„ íƒí•˜ì„¸ìš”:\", flush=True)\n",
    "            print(\"1. ì¬ê²€ìƒ‰(ìƒˆë¡œìš´ ì¿¼ë¦¬)\", flush=True)\n",
    "            print(\"2. ì¢…ë£Œ\", flush=True)\n",
    "            menu = input(\"ë©”ë‰´ ë²ˆí˜¸ ì…ë ¥: \").strip()\n",
    "            if menu == \"1\":\n",
    "                break  # while True -> ì¬ê²€ìƒ‰\n",
    "            elif menu == \"2\":\n",
    "                print(\"\\ní”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.\")\n",
    "                return\n",
    "            else:\n",
    "                print(\"ì˜ëª»ëœ ì…ë ¥ì…ë‹ˆë‹¤. ë‹¤ì‹œ ì„ íƒí•´ ì£¼ì„¸ìš”.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lang_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
